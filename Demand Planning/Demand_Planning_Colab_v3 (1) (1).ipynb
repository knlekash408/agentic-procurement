{"cells":[{"cell_type":"markdown","metadata":{"id":"69pDBHaXxoRq"},"source":["# Demand Planning Tool - Production Forecast v3\n","\n","This notebook creates a comprehensive demand planning analysis with:\n","- Historical sales analysis by Product Name/SKU and channel\n","- **Improved statistical forecasts** using 2-year product-type seasonality + weighted trend\n","- Seasonal indices calculated at **product type level** (pooled across all SKUs in a type)\n","- Recency-weighted trend per SKU (recent months weighted more heavily)\n","- Forecast pivot tabs show last 2 years of actuals alongside forecast for direct comparison\n","- Export to Google Sheets\n","\n","## Forecasting Methodology (v3)\n","- **Seasonality**: Pooled across all SKUs within a product type, using the last 24 months of TOTAL channel data. Seasonal indices are stable because they draw on the full volume of a product type rather than a single item.\n","- **Trend**: Linear trend via weighted least-squares on each SKU's last 12 months (deseasonalized). Recent months weighted up to 12√ó heavier.\n","- **Base Level**: Exponentially weighted moving average of last 12 months per SKU.\n","- **Manual Growth Override**: Optional annual growth rate applied on top of data-driven trend.\n","\n","## Setup Instructions\n","1. Upload your CSV file when prompted\n","2. Run all cells in order\n","3. Authenticate with Google when prompted\n","4. The output will be saved to your Google Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"20u6smrPxoRt","executionInfo":{"status":"ok","timestamp":1771431483047,"user_tz":480,"elapsed":13721,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[],"source":["# Install required packages\n","!pip install gspread oauth2client pandas numpy openpyxl scipy -q"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"sWqoO9hNxoRu","executionInfo":{"status":"ok","timestamp":1771431486258,"user_tz":480,"elapsed":3203,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[],"source":["# Import libraries\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime, timedelta\n","from scipy import stats\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from google.colab import files\n","from google.colab import auth\n","import gspread\n","from oauth2client.client import GoogleCredentials"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"TC4b68HvxoRu","outputId":"5a7494cd-93e0-44bd-abbd-ca7500845a57","executionInfo":{"status":"ok","timestamp":1771431508836,"user_tz":480,"elapsed":22576,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Please upload your sales data CSV file:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-ee0a00b6-e1d9-43cf-ab0d-bd4feef1d66a\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-ee0a00b6-e1d9-43cf-ab0d-bd4feef1d66a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving _SELECT_mts_created_date_mts_products__master__id_mts_products___202602171733.csv to _SELECT_mts_created_date_mts_products__master__id_mts_products___202602171733.csv\n","\n","File '_SELECT_mts_created_date_mts_products__master__id_mts_products___202602171733.csv' uploaded successfully!\n"]}],"source":["# Upload your CSV file\n","print(\"Please upload your sales data CSV file:\")\n","uploaded = files.upload()\n","filename = list(uploaded.keys())[0]\n","print(f\"\\nFile '{filename}' uploaded successfully!\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"id":"yHBcW-ARxoRu","outputId":"105722f0-d2e2-4eb8-cf7d-2137e80c942c","executionInfo":{"status":"ok","timestamp":1771431510843,"user_tz":480,"elapsed":326,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data from: _SELECT_mts_created_date_mts_products__master__id_mts_products___202602171733.csv\n","‚úÖ Data loaded successfully\n","   Total rows: 84,579\n","   Date range: 2022-01-01 to 2026-02-16\n","   Channels: ['Direct-to-Consumer' 'Wholesale' 'Kristina Holey']\n","   Unique SKUs: 275\n","\n","First few rows:\n"]},{"output_type":"display_data","data":{"text/plain":["  created_date products__master__id products__variants__sku  \\\n","0   2022-01-01          19215247238                FG-10047   \n","1   2022-01-01          19215265286                FG-10029   \n","2   2022-01-01          29370167116                FG-10006   \n","3   2022-01-01       32378481934372                FG-10005   \n","4   2022-01-01          29370177804                FG-10038   \n","\n","                        products__variants__title  \\\n","0  Vitamins C + E + Ferulic Serum - Retail (1 oz)   \n","1              Protective Day Oil - Retail (1 oz)   \n","2           Barrier Restore Serum - Retail (1 oz)   \n","3           Barrier Lipid Complex - Retail (1 oz)   \n","4               Soothing B3 Serum - Retail (1 oz)   \n","\n","    products__root_product__title products__product_type products__vendor  \\\n","0  Vitamins C + E + Ferulic Serum                  SERUM  Marie Veronique   \n","1              Protective Day Oil                    OIL  Marie Veronique   \n","2           Barrier Restore Serum                  SERUM  Marie Veronique   \n","3           Barrier Lipid Complex                    OIL  Marie Veronique   \n","4               Soothing B3 Serum                  SERUM  Marie Veronique   \n","\n","       orders__source  quantity  price  total_gross_sales  total_net_sales  \\\n","0  Direct-to-Consumer         7   90.0              630.0            630.0   \n","1  Direct-to-Consumer         7   65.0              455.0            447.2   \n","2  Direct-to-Consumer         4  110.0              440.0            440.0   \n","3  Direct-to-Consumer         4   95.0              380.0            380.0   \n","4  Direct-to-Consumer         3   90.0              270.0            270.0   \n","\n","   total_sales  \n","0        630.0  \n","1        447.2  \n","2        440.0  \n","3        380.0  \n","4        270.0  "],"text/html":["\n","  <div id=\"df-44fa800f-b652-482c-89ec-b806ba00cae7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>created_date</th>\n","      <th>products__master__id</th>\n","      <th>products__variants__sku</th>\n","      <th>products__variants__title</th>\n","      <th>products__root_product__title</th>\n","      <th>products__product_type</th>\n","      <th>products__vendor</th>\n","      <th>orders__source</th>\n","      <th>quantity</th>\n","      <th>price</th>\n","      <th>total_gross_sales</th>\n","      <th>total_net_sales</th>\n","      <th>total_sales</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022-01-01</td>\n","      <td>19215247238</td>\n","      <td>FG-10047</td>\n","      <td>Vitamins C + E + Ferulic Serum - Retail (1 oz)</td>\n","      <td>Vitamins C + E + Ferulic Serum</td>\n","      <td>SERUM</td>\n","      <td>Marie Veronique</td>\n","      <td>Direct-to-Consumer</td>\n","      <td>7</td>\n","      <td>90.0</td>\n","      <td>630.0</td>\n","      <td>630.0</td>\n","      <td>630.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022-01-01</td>\n","      <td>19215265286</td>\n","      <td>FG-10029</td>\n","      <td>Protective Day Oil - Retail (1 oz)</td>\n","      <td>Protective Day Oil</td>\n","      <td>OIL</td>\n","      <td>Marie Veronique</td>\n","      <td>Direct-to-Consumer</td>\n","      <td>7</td>\n","      <td>65.0</td>\n","      <td>455.0</td>\n","      <td>447.2</td>\n","      <td>447.2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022-01-01</td>\n","      <td>29370167116</td>\n","      <td>FG-10006</td>\n","      <td>Barrier Restore Serum - Retail (1 oz)</td>\n","      <td>Barrier Restore Serum</td>\n","      <td>SERUM</td>\n","      <td>Marie Veronique</td>\n","      <td>Direct-to-Consumer</td>\n","      <td>4</td>\n","      <td>110.0</td>\n","      <td>440.0</td>\n","      <td>440.0</td>\n","      <td>440.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022-01-01</td>\n","      <td>32378481934372</td>\n","      <td>FG-10005</td>\n","      <td>Barrier Lipid Complex - Retail (1 oz)</td>\n","      <td>Barrier Lipid Complex</td>\n","      <td>OIL</td>\n","      <td>Marie Veronique</td>\n","      <td>Direct-to-Consumer</td>\n","      <td>4</td>\n","      <td>95.0</td>\n","      <td>380.0</td>\n","      <td>380.0</td>\n","      <td>380.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022-01-01</td>\n","      <td>29370177804</td>\n","      <td>FG-10038</td>\n","      <td>Soothing B3 Serum - Retail (1 oz)</td>\n","      <td>Soothing B3 Serum</td>\n","      <td>SERUM</td>\n","      <td>Marie Veronique</td>\n","      <td>Direct-to-Consumer</td>\n","      <td>3</td>\n","      <td>90.0</td>\n","      <td>270.0</td>\n","      <td>270.0</td>\n","      <td>270.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44fa800f-b652-482c-89ec-b806ba00cae7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-44fa800f-b652-482c-89ec-b806ba00cae7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-44fa800f-b652-482c-89ec-b806ba00cae7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"    raise\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"created_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2022-01-01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"products__master__id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"19215265286\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"products__variants__sku\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"FG-10029\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"products__variants__title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Protective Day Oil - Retail (1 oz)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"products__root_product__title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Protective Day Oil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"products__product_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"OIL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"products__vendor\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Marie Veronique\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"orders__source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Direct-to-Consumer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quantity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.20185174601965,\n        \"min\": 65.0,\n        \"max\": 110.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          65.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_gross_sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 131.05342422081156,\n        \"min\": 270.0,\n        \"max\": 630.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          455.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_net_sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 130.8020183330517,\n        \"min\": 270.0,\n        \"max\": 630.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          447.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 130.8020183330517,\n        \"min\": 270.0,\n        \"max\": 630.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          447.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["# ============================================================\n","# STEP 2: LOAD SALES DATA\n","# ============================================================\n","# Upload your sales CSV file or specify a pre-uploaded filename\n","# ============================================================\n","\n","# Option 1: Upload a new sales CSV file (uncomment to use)\n","# uploaded = files.upload()\n","# if uploaded:\n","#     filename = list(uploaded.keys())[0]\n","\n","# Option 2: Use a pre-uploaded file (default)\n","filename = '_SELECT_mts_created_date_mts_products__master__id_mts_products___202602171733.csv'  # Change this to your uploaded filename\n","\n","print(f\"Loading data from: {filename}\")\n","\n","try:\n","    df = pd.read_csv(filename)\n","\n","    print(f\"‚úÖ Data loaded successfully\")\n","    print(f\"   Total rows: {len(df):,}\")\n","    print(f\"   Date range: {df['created_date'].min()} to {df['created_date'].max()}\")\n","    print(f\"   Channels: {df['orders__source'].unique()}\")\n","    print(f\"   Unique SKUs: {df['products__variants__sku'].nunique()}\")\n","    print(f\"\\nFirst few rows:\")\n","    display(df.head())\n","\n","except FileNotFoundError:\n","    print(f\"‚ö†Ô∏è  File not found: {filename}\")\n","    print(\"   Please upload the file first, or uncomment the upload section above.\")\n","    raise\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è  Error loading file: {e}\")\n","    raise\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bps7X3avxoRu","outputId":"736b78b2-b5c9-498e-ee0b-3a3aa6eac5d8","executionInfo":{"status":"ok","timestamp":1771431524203,"user_tz":480,"elapsed":84,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Data aggregated to monthly level\n","Monthly records: 7,654\n","\n","Sample SKU ‚Üí Product Name mapping:\n","products__variants__sku                            product_name products__product_type\n","        $20 Reward Code                         $20 Reward Code                   None\n","     000000000300088687 Quinton Hypertonic Ampoules 30 Servings                   None\n","           500-V0-40-DR                      Protective Day Oil                    OIL\n","           BLANKET-V4-1       HigherDose Blanket with No Insert                   WRAP\n","      BLANKET-W-1INSERT      HigherDose Blanket with One Insert                   WRAP\n","      BLANKET-W-3INSERT    Infrared Sauna Blanket by HigherDOSE                   WRAP\n","      BOTTLES+ CLOSURES                       BOTTLES+ CLOSURES                   None\n","                 CC3302                     The Cleansing Coins                   None\n","  DHL EXPRESS WORLDWIDE                   DHL EXPRESS WORLDWIDE                   None\n","              FG-100004                     Balancing Hypotonic                 BUNDLE\n"]}],"source":["# Prepare data for analysis\n","df['created_date'] = pd.to_datetime(df['created_date'])\n","df['year_month'] = df['created_date'].dt.to_period('M')\n","df['year'] = df['created_date'].dt.year\n","df['month'] = df['created_date'].dt.month\n","\n","# Aggregate to monthly level by SKU and channel\n","monthly_data = df.groupby(['year_month', 'products__variants__sku', 'orders__source'])['quantity'].sum().reset_index()\n","monthly_data['year_month_str'] = monthly_data['year_month'].astype(str)\n","\n","# Get SKU details\n","sku_details = df.groupby('products__variants__sku').agg({\n","    'products__variants__title': 'first',\n","    'products__root_product__title': 'first',\n","    'products__product_type': 'first'\n","}).reset_index()\n","\n","# Standardize product_name: prefer root product title, fall back to variant title\n","sku_details['product_name'] = sku_details['products__root_product__title'].fillna(\n","    sku_details['products__variants__title']\n",")\n","\n","print(\"Data aggregated to monthly level\")\n","print(f\"Monthly records: {len(monthly_data):,}\")\n","print(f\"\\nSample SKU ‚Üí Product Name mapping:\")\n","print(sku_details[['products__variants__sku', 'product_name', 'products__product_type']].head(10).to_string(index=False))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTc2fZ7mxoRv","outputId":"9f4ef1d0-f308-41bb-d1cd-5c235f592ac6","executionInfo":{"status":"ok","timestamp":1771431534342,"user_tz":480,"elapsed":55,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Seasonal indices built for 25 product types\n","\n","Product types found:\n","  ‚Ä¢ BACKBAR\n","  ‚Ä¢ BODY\n","  ‚Ä¢ BOOK\n","  ‚Ä¢ BUNDLE\n","  ‚Ä¢ CLEANSER\n","  ‚Ä¢ CONDITIONER\n","  ‚Ä¢ DUO\n","  ‚Ä¢ FREEGIFT_HIDDEN\n","  ‚Ä¢ GUA SHA\n","  ‚Ä¢ KIT\n","  ‚Ä¢ MASK\n","  ‚Ä¢ MIST\n","  ‚Ä¢ OIL\n","  ‚Ä¢ PACKAGING\n","  ‚Ä¢ PROTECT\n","  ‚Ä¢ SAMPLE\n","  ‚Ä¢ SERUM\n","  ‚Ä¢ SET\n","  ‚Ä¢ SHAMPOO\n","  ‚Ä¢ SOAP & LOTION DISPENSERS\n","  ‚Ä¢ SUNSCREEN\n","  ‚Ä¢ SUPPLEMENT\n","  ‚Ä¢ TINCTURE\n","  ‚Ä¢ VIRTUAL CONSULTATION\n","  ‚Ä¢ WRAP\n"]}],"source":["# ============================================================\n","# STEP 1: BUILD PRODUCT-TYPE SEASONAL INDICES\n","# ============================================================\n","# Seasonality is pooled across ALL SKUs within each product type,\n","# using the last 24 months of TOTAL channel data.\n","# This gives stable, noise-resistant seasonal patterns.\n","# ============================================================\n","\n","MONTH_NAMES = {\n","    1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr',\n","    5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug',\n","    9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n","}\n","\n","def build_product_type_seasonal_indices(monthly_data, sku_details, cutoff='2026-01'):\n","    \"\"\"\n","    Calculate seasonal indices per product type per calendar month.\n","    Uses TOTAL channel (all channels combined) for the last 24 months up to cutoff.\n","    Returns a dict: {product_type: {month_number: index}}\n","    \"\"\"\n","    # Work from TOTAL channel (sum all channels per SKU-month)\n","    total_monthly = monthly_data.groupby(['year_month_str', 'products__variants__sku'])['quantity'].sum().reset_index()\n","\n","    # Attach product type\n","    total_monthly = total_monthly.merge(\n","        sku_details[['products__variants__sku', 'products__product_type']],\n","        on='products__variants__sku', how='left'\n","    )\n","\n","    # Filter to last 24 months up to cutoff\n","    cutoff_period = pd.Period(cutoff, freq='M')\n","    start_period = cutoff_period - 23  # 24 months window\n","    total_monthly = total_monthly[\n","        (total_monthly['year_month_str'] >= str(start_period)) &\n","        (total_monthly['year_month_str'] <= cutoff)\n","    ].copy()\n","\n","    total_monthly['cal_month'] = total_monthly['year_month_str'].str[5:7].astype(int)\n","\n","    # Sum quantity by product_type + calendar month (across all SKUs and both years)\n","    pt_monthly = total_monthly.groupby(['products__product_type', 'cal_month'])['quantity'].sum().reset_index()\n","\n","    # Calculate average monthly quantity per product type per calendar month\n","    # (divide by number of years represented ‚Äî up to 2)\n","    # Then normalize so indices average to 1.0 across the 12 months\n","    seasonal_indices = {}\n","    product_types = pt_monthly['products__product_type'].unique()\n","\n","    for pt in product_types:\n","        pt_data = pt_monthly[pt_monthly['products__product_type'] == pt].copy()\n","\n","        # Build month ‚Üí avg quantity mapping\n","        month_qty = {}\n","        for _, row in pt_data.iterrows():\n","            month_qty[int(row['cal_month'])] = row['quantity']\n","\n","        # Fill missing months with average of available months\n","        if len(month_qty) > 0:\n","            avg_qty = np.mean(list(month_qty.values()))\n","        else:\n","            avg_qty = 1.0\n","\n","        for m in range(1, 13):\n","            if m not in month_qty:\n","                month_qty[m] = avg_qty\n","\n","        # Normalize: each index = month_qty / (sum of all months / 12)\n","        grand_avg = np.mean([month_qty[m] for m in range(1, 13)])\n","        if grand_avg > 0:\n","            indices = {m: month_qty[m] / grand_avg for m in range(1, 13)}\n","        else:\n","            indices = {m: 1.0 for m in range(1, 13)}\n","\n","        seasonal_indices[pt] = indices\n","\n","    return seasonal_indices\n","\n","\n","# Build product-type seasonal indices\n","pt_seasonal_indices = build_product_type_seasonal_indices(monthly_data, sku_details)\n","\n","print(f\"‚úÖ Seasonal indices built for {len(pt_seasonal_indices)} product types\")\n","print(\"\\nProduct types found:\")\n","for pt in sorted(pt_seasonal_indices.keys()):\n","    print(f\"  ‚Ä¢ {pt}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NM8yL0axoRv","outputId":"a5de8291-0ada-4ecc-f2a9-39ba53b8097d","executionInfo":{"status":"ok","timestamp":1771431551197,"user_tz":480,"elapsed":7,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["üìä SEASONAL INDICES BY PRODUCT TYPE AND MONTH\n","   (Based on last 24 months of TOTAL channel data)\n","   Index > 1.0 = stronger than annual average | Index < 1.0 = weaker than annual average\n","\n","            Product Type   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n","                 BACKBAR 0.842 1.000 1.000 1.000 1.000 1.474 1.684 0.947 1.158 0.526 0.737 0.632\n","                    BODY 0.837 0.378 0.610 0.717 0.511 0.589 0.567 1.083 0.646 2.992 1.577 1.493\n","                    BOOK 0.589 0.547 1.221 0.926 0.968 1.221 1.011 0.547 0.758 0.800 1.474 1.937\n","                  BUNDLE 1.585 0.740 0.820 0.563 0.353 0.282 0.311 0.458 0.664 0.370 4.898 0.954\n","                CLEANSER 0.959 1.051 1.037 0.790 0.881 0.879 1.027 0.921 1.214 0.806 1.561 0.877\n","             CONDITIONER 1.000 1.000 1.103 0.828 1.655 0.276 0.828 1.103 1.379 0.828 1.000 1.000\n","                     DUO 1.000 0.996 1.371 0.972 1.021 1.156 0.947 1.175 1.027 0.935 0.400 1.000\n","         FREEGIFT_HIDDEN 0.008 0.280 0.011 0.118 5.761 0.063 0.002 0.006 1.000 0.143 2.853 1.755\n","                 GUA SHA 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n","                     KIT 1.000 0.370 0.485 0.469 0.822 0.238 5.566 0.008 1.000 1.000 1.000 0.041\n","                    MASK 0.872 0.883 0.828 0.731 1.393 0.728 1.090 1.061 1.325 0.787 1.452 0.851\n","                    MIST 0.850 1.049 0.913 0.754 0.774 0.953 1.011 1.056 1.195 0.867 1.808 0.771\n","                     OIL 0.947 0.997 1.002 0.842 0.848 0.775 0.942 1.022 1.257 0.716 1.837 0.816\n","               PACKAGING 0.596 1.006 0.918 1.070 0.805 1.239 0.805 1.135 1.344 1.078 1.247 0.757\n","                 PROTECT 0.420 1.000 1.000 0.092 4.388 1.440 0.601 1.071 0.377 0.359 0.854 0.398\n","                  SAMPLE 1.000 1.998 0.017 0.391 2.565 1.000 1.000 1.000 1.000 1.000 1.000 0.028\n","                   SERUM 0.884 1.012 1.005 0.791 0.767 0.753 0.982 1.026 1.350 0.697 1.933 0.799\n","                     SET 1.000 0.841 1.230 0.999 1.335 1.241 0.967 1.220 0.883 0.978 0.305 1.000\n","                 SHAMPOO 1.000 1.000 1.000 0.750 1.750 0.250 0.500 1.250 1.250 1.250 1.000 1.000\n","SOAP & LOTION DISPENSERS 1.000 1.000 1.019 0.340 1.528 0.679 0.679 1.019 1.019 0.340 2.377 1.000\n","               SUNSCREEN 0.744 0.780 0.888 1.047 1.287 1.009 1.113 0.938 1.049 0.602 1.777 0.766\n","              SUPPLEMENT 0.515 0.736 0.663 0.147 0.957 1.914 1.840 0.810 0.883 0.957 1.914 0.663\n","                TINCTURE 0.296 0.741 2.222 0.296 0.741 2.519 1.481 0.741 1.630 0.593 0.296 0.444\n","    VIRTUAL CONSULTATION 1.983 1.190 1.091 1.190 0.893 0.893 0.793 0.595 0.298 0.992 0.793 1.289\n","                    WRAP 1.000 0.429 1.000 1.000 1.000 1.000 1.714 1.000 1.000 1.000 0.857 1.000\n","\n","Note: Indices within each product type sum to 12.0 (average = 1.0)\n"]}],"source":["# ============================================================\n","# STEP 2: DISPLAY SEASONALITY TABLE (Product Type √ó Month)\n","# ============================================================\n","# This shows the seasonal index for each product type by month.\n","# Index > 1.0 = that month is stronger than average\n","# Index < 1.0 = that month is weaker than average\n","# ============================================================\n","\n","seasonality_rows = []\n","for pt, indices in sorted(pt_seasonal_indices.items()):\n","    row = {'Product Type': pt}\n","    for m in range(1, 13):\n","        row[MONTH_NAMES[m]] = round(indices[m], 3)\n","    seasonality_rows.append(row)\n","\n","seasonality_display_df = pd.DataFrame(seasonality_rows)\n","\n","print(\"üìä SEASONAL INDICES BY PRODUCT TYPE AND MONTH\")\n","print(\"   (Based on last 24 months of TOTAL channel data)\")\n","print(\"   Index > 1.0 = stronger than annual average | Index < 1.0 = weaker than annual average\")\n","print()\n","print(seasonality_display_df.to_string(index=False))\n","print()\n","print(\"Note: Indices within each product type sum to 12.0 (average = 1.0)\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xlCSnqnxxoRv","outputId":"2772bf18-f9df-4472-9e72-03f2ab614f4e","executionInfo":{"status":"ok","timestamp":1771431618367,"user_tz":480,"elapsed":46,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Forecasting engine loaded (product-type seasonality)\n"]}],"source":["# ============================================================\n","# STEP 3: FORECASTING ENGINE (using product-type seasonality)\n","# ============================================================\n","\n","def calculate_weighted_trend(deseasonalized_values):\n","    \"\"\"\n","    Estimate trend (units/month) using weighted least-squares.\n","    Weights increase linearly so most recent = window weight, oldest = 1.\n","    \"\"\"\n","    n = len(deseasonalized_values)\n","    if n < 4:\n","        return 0.0\n","\n","    weights = np.arange(1, n + 1, dtype=float)\n","    x = np.arange(n, dtype=float)\n","    w = weights\n","    wx = (w * x).sum()\n","    wy = (w * deseasonalized_values).sum()\n","    wxx = (w * x * x).sum()\n","    wxy = (w * x * deseasonalized_values).sum()\n","    wsum = w.sum()\n","\n","    denom = wsum * wxx - wx * wx\n","    if abs(denom) < 1e-10:\n","        return 0.0\n","\n","    slope = (wsum * wxy - wx * wy) / denom\n","    return slope\n","\n","\n","def exponential_weighted_mean(arr, alpha=0.15):\n","    \"\"\"\n","    Exponentially weighted mean ‚Äî most recent observation has highest weight.\n","    \"\"\"\n","    n = len(arr)\n","    weights = np.array([(1 - alpha) ** (n - 1 - i) for i in range(n)])\n","    return np.dot(weights, arr) / weights.sum()\n","\n","\n","def calculate_forecast(historical_values, calendar_months, product_type,\n","                       pt_seasonal_indices, forecast_calendar_months,\n","                       growth_rate=0.0):\n","    \"\"\"\n","    Forecast using PRODUCT TYPE seasonal indices.\n","\n","    Parameters:\n","    - historical_values       : numpy array of quantities (sorted oldest‚Üínewest)\n","    - calendar_months         : numpy array of calendar month numbers (1-12) for history\n","    - product_type            : string product type for seasonal index lookup\n","    - pt_seasonal_indices     : dict {product_type: {month: index}}\n","    - forecast_calendar_months: list of calendar month numbers (1-12) for forecast\n","    - growth_rate             : manual annual growth override\n","    \"\"\"\n","    n = len(historical_values)\n","    forecast_periods = len(forecast_calendar_months)\n","\n","    # Get seasonal indices for this product type (fallback to flat 1.0)\n","    seasonal_indices = pt_seasonal_indices.get(product_type, {m: 1.0 for m in range(1, 13)})\n","\n","    if n < 4:\n","        avg = np.mean(historical_values) if n > 0 else 0\n","        forecasts = []\n","        for cal_m in forecast_calendar_months:\n","            forecasts.append(int(round(max(0, avg * seasonal_indices.get(cal_m, 1.0)))))\n","        return forecasts\n","\n","    # Deseasonalize last 12 months of history\n","    window = min(n, 12)\n","    recent_vals = historical_values[-window:]\n","    recent_months = calendar_months[-window:]\n","\n","    deseason_recent = np.array([\n","        v / seasonal_indices.get(int(m), 1.0) if seasonal_indices.get(int(m), 1.0) > 0 else v\n","        for v, m in zip(recent_vals, recent_months)\n","    ])\n","\n","    # Base level: exponentially weighted mean of deseasonalized recent\n","    base_level = exponential_weighted_mean(deseason_recent, alpha=0.15)\n","\n","    # Trend: weighted least squares on deseasonalized recent\n","    trend_slope = calculate_weighted_trend(deseason_recent)\n","\n","    # Cap trend at ¬±2.5% of base per month\n","    max_slope = base_level * 0.025 if base_level > 0 else 1.0\n","    trend_slope = np.clip(trend_slope, -max_slope, max_slope)\n","\n","    # Manual growth ‚Üí monthly multiplier\n","    monthly_growth = (1 + growth_rate) ** (1 / 12) - 1\n","\n","    forecasts = []\n","    for i, cal_month in enumerate(forecast_calendar_months):\n","        projected_base = base_level + trend_slope * (i + 1)\n","        growth_factor = (1 + monthly_growth) ** (i + 1)\n","        projected_base *= growth_factor\n","        seasonal_factor = seasonal_indices.get(int(cal_month), 1.0)\n","        forecast = projected_base * seasonal_factor\n","        forecasts.append(int(round(max(0, forecast))))\n","\n","    return forecasts\n","\n","\n","print(\"‚úÖ Forecasting engine loaded (product-type seasonality)\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-n5KueGFxoRw","outputId":"00bbb48c-89f0-4e3f-b0ad-6d1a0c626c3a","executionInfo":{"status":"ok","timestamp":1771431623053,"user_tz":480,"elapsed":5,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Per-Channel Growth Rate Overrides:\n","  Direct-to-Consumer        +0.0% annually\n","  Wholesale                 +0.0% annually\n","  TOTAL                     +0.0% annually\n"]}],"source":["# ============================================================================\n","# TUNE YOUR FORECAST GROWTH RATES HERE ‚Äî per channel\n","# ============================================================================\n","# Set an annual growth rate for each channel independently.\n","# This is a MANUAL OVERRIDE on top of the data-driven statistical trend.\n","# Leave at 0.0 to rely purely on the model's trend for that channel.\n","#\n","# Examples:\n","#   0.10  = add 10% annual growth on top of data trend\n","#   0.05  = add 5% growth\n","#   0.0   = pure statistical forecast (recommended starting point)\n","#  -0.10  = force 10% decline on top of data trend\n","#  -0.20  = force 20% decline (use to rein in an over-optimistic channel)\n","#\n","# TOTAL is computed independently from DTC + Wholesale, so set it\n","# separately if you want the TOTAL tab to reflect a blended view.\n","# ============================================================================\n","\n","CHANNEL_GROWTH_RATES = {\n","    'Direct-to-Consumer': 0.0,   # ‚Üê tune DTC here\n","    'Wholesale':          0.0,   # ‚Üê tune Wholesale here\n","    'TOTAL':              0.0,   # ‚Üê tune Total here\n","}\n","\n","print(\"Per-Channel Growth Rate Overrides:\")\n","for ch, rate in CHANNEL_GROWTH_RATES.items():\n","    print(f\"  {ch:<25} {rate*100:+.1f}% annually\")\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbPdz0eRoAby","outputId":"47cbc26e-f3f6-4419-c2d0-96934f4699e2","executionInfo":{"status":"ok","timestamp":1771431633732,"user_tz":480,"elapsed":7,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"source":["# Active SKU List (hardcoded)\n","ACTIVE_SKUS = [\n","    'FG-10082', 'FG-90004', 'FG-10004', 'FG-80004', 'FG-20004',\n","    'FG-90005', 'FG-10005', 'FG-90006', 'FG-10006', 'FG-90067',\n","    'FG-10081', 'FG-20081', 'FG-90007', 'FG-10007', 'FG-90103',\n","    'FG-10103', 'FG-90008', 'FG-10083', 'FG-10101', 'FG-90012',\n","    'FG-10014XL', 'FG-10014L', 'FG-10014M', 'FG-10094', 'FG-10022',\n","    'FG-90017', 'FG-10017', 'FG-10018', 'FG-10019', 'FG-90022',\n","    'FG-10025', 'FG-10026', 'FG-20026', 'FG-90028', 'FG-10028',\n","    'FG-90029', 'FG-10029', 'FG-90030', 'FG-10030', 'FG-20030',\n","    'FG-90100', 'FG-10100', 'FG-90034', 'FG-10034', 'FG-90036',\n","    'FG-10036', 'FG-90099', 'FG-10099', 'FG-10068', 'FG-90038',\n","    'FG-10038', 'FG-90102', 'FG-10102', 'FG-90104', 'FG-10104',\n","    'FG-90047', 'FG-10047'\n","]\n","\n","active_skus_from_file = set(ACTIVE_SKUS)\n","print(f\"Active SKUs loaded (hardcoded): {len(active_skus_from_file)}\")\n","print(f\"Sample: {list(active_skus_from_file)[:5]}\")\n"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Active SKUs loaded (hardcoded): 57\n","Sample: ['FG-90067', 'FG-10014XL', 'FG-90104', 'FG-10104', 'FG-10014M']\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPMKLqpWxoRw","outputId":"218834e6-1a1e-49ab-c381-2f8857e5a7fb","executionInfo":{"status":"ok","timestamp":1771431637482,"user_tz":480,"elapsed":506,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Active SKU filter: 57 SKUs\n","Matching SKUs (in both filter and data): 57\n","\n","Generating forecasts for Direct-to-Consumer...\n","\n","Generating forecasts for Wholesale...\n","\n","Generating forecasts for TOTAL...\n","\n","‚úÖ Forecasts generated: 1,628 records\n","   Unique SKUs forecasted (TOTAL channel): 57\n","   SKUs skipped per channel: {'Direct-to-Consumer': 183, 'Wholesale': 93, 'TOTAL': 218}\n","\n","üìã Filter was applied: 57 SKUs from file\n","   57 SKUs actually forecasted\n"]}],"source":["# ============================================================\n","# STEP 4: GENERATE FORECASTS\n","# ============================================================\n","# ACTIVE SKU FILTER: Reads from a CSV file of active SKUs.\n","# You can either upload a new file or use the default filename.\n","# Expected format: Single column with SKU codes (header optional).\n","# ============================================================\n","\n","forecast_months = pd.period_range('2026-02', '2026-12', freq='M')\n","forecast_cal_months = [p.month for p in forecast_months]\n","\n","all_channels = ['Direct-to-Consumer', 'Wholesale', 'TOTAL']\n","\n","# ‚îÄ‚îÄ Active SKU filter already set by previous cell ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","# active_skus_from_file is defined above with the hardcoded list\n","\n","print(f\"\\nActive SKU filter: {len(active_skus_from_file)} SKUs\")\n","\n","# Debug: show what SKUs are in data vs filter\n","all_data_skus = set(sku_details['products__variants__sku'].unique())\n","matching = active_skus_from_file & all_data_skus\n","print(f\"Matching SKUs (in both filter and data): {len(matching)}\")\n","\n","if len(matching) == 0:\n","    print(\"‚ö†Ô∏è  WARNING: NO MATCHING SKUs!\")\n","    print(\"   Proceeding to forecast ALL SKUs.\")\n","    active_skus_from_file = set()\n","\n","# --- Generate forecasts (active SKUs only) ---\n","forecast_results = []\n","skipped_counts = {ch: 0 for ch in all_channels}\n","forecasted_skus = set()\n","\n","for channel in all_channels:\n","    print(f\"\\nGenerating forecasts for {channel}...\")\n","\n","    if channel == 'TOTAL':\n","        channel_data = monthly_data.groupby(['year_month_str', 'products__variants__sku'])['quantity'].sum().reset_index()\n","    else:\n","        channel_data = monthly_data[monthly_data['orders__source'] == channel].copy()\n","\n","    channel_skus = channel_data['products__variants__sku'].unique()\n","\n","    for sku in channel_skus:\n","        sku_match = sku_details[sku_details['products__variants__sku'] == sku]\n","        if len(sku_match) == 0:\n","            continue\n","        sku_info = sku_match.iloc[0]\n","        product_type = sku_info['products__product_type']\n","\n","        # ACTIVE SKU CHECK ‚Äî only forecast if SKU is in uploaded file\n","        # If file is empty or failed to load, forecast all\n","        if len(active_skus_from_file) > 0 and sku not in active_skus_from_file:\n","            skipped_counts[channel] += 1\n","            continue\n","\n","        sku_data = channel_data[channel_data['products__variants__sku'] == sku]\n","\n","        # Historical data up to cutoff, sorted chronologically\n","        HISTORY_CUTOFF = '2026-01'\n","        historical = sku_data[sku_data['year_month_str'] <= HISTORY_CUTOFF].sort_values('year_month_str')\n","        hist_values = historical['quantity'].values.astype(float)\n","        hist_cal_months = np.array([int(ym[5:7]) for ym in historical['year_month_str'].values])\n","\n","        # Forecast using product-type seasonality\n","        forecasts = calculate_forecast(\n","            hist_values,\n","            hist_cal_months,\n","            product_type,\n","            pt_seasonal_indices,\n","            forecast_cal_months,\n","            CHANNEL_GROWTH_RATES.get(channel, 0.0)\n","        )\n","\n","        for month, forecast_qty in zip(forecast_months, forecasts):\n","            forecast_results.append({\n","                'channel': channel,\n","                'product_name': sku_info['product_name'],\n","                'sku': sku,\n","                'product_type': product_type,\n","                'month': str(month),\n","                'forecast_qty': forecast_qty\n","            })\n","\n","        if channel == 'TOTAL':\n","            forecasted_skus.add(sku)\n","\n","forecast_df = pd.DataFrame(forecast_results)\n","print(f\"\\n‚úÖ Forecasts generated: {len(forecast_df):,} records\")\n","print(f\"   Unique SKUs forecasted (TOTAL channel): {len(forecasted_skus)}\")\n","print(f\"   SKUs skipped per channel: { {k: v for k, v in skipped_counts.items()} }\")\n","\n","# Final verification\n","if len(active_skus_from_file) > 0:\n","    print(f\"\\nüìã Filter was applied: {len(active_skus_from_file)} SKUs from file\")\n","    print(f\"   {len(forecasted_skus)} SKUs actually forecasted\")\n","    if len(forecasted_skus) != len(matching):\n","        print(f\"   ‚ö†Ô∏è  Expected {len(matching)} forecasted SKUs (matching count)\")\n","else:\n","    print(f\"\\n‚ö†Ô∏è  No filter applied - all {len(forecasted_skus)} SKUs in data were forecasted\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P3q0HbsDxoRw","outputId":"2239ef1b-f72f-4709-82c7-58b1c803fca1","executionInfo":{"status":"ok","timestamp":1771431667118,"user_tz":480,"elapsed":71,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Comparison pivots built (2024 actuals | 2025 actuals | 2026 forecast)\n","Columns: 2024-01 ‚Üí 2026-12 (36 months)\n"]}],"source":["# ============================================================\n","# STEP 5: BUILD FORECAST COMPARISON PIVOT\n","# (2024 actuals | 2025 actuals | 2026 forecast ‚Äî all months)\n","# ============================================================\n","\n","def build_comparison_pivot(channel, monthly_data, forecast_df, sku_details):\n","    \"\"\"\n","    Build a pivot table showing:\n","      Rows: Product Name | SKU\n","      Columns: 2024-01 ... 2024-12, 2025-01 ... 2025-12, 2026-01 (actual), 2026-02 ... 2026-12 (forecast)\n","    Adds a row-level label prefix so actuals vs forecast are clear.\n","    \"\"\"\n","    # --- Historical actuals ---\n","    if channel == 'TOTAL':\n","        hist_data = monthly_data.groupby(['year_month_str', 'products__variants__sku'])['quantity'].sum().reset_index()\n","    else:\n","        hist_data = monthly_data[monthly_data['orders__source'] == channel].copy()\n","        hist_data = hist_data[['year_month_str', 'products__variants__sku', 'quantity']]\n","\n","    # Only keep last 2 years of actuals (2024 + 2025) plus 2026-01\n","    hist_data = hist_data[\n","        (hist_data['year_month_str'] >= '2024-01') &\n","        (hist_data['year_month_str'] <= '2026-01')\n","    ].copy()\n","\n","    hist_data = hist_data.merge(\n","        sku_details[['products__variants__sku', 'product_name']],\n","        on='products__variants__sku', how='left'\n","    )\n","    hist_data['type_flag'] = 'Actual'\n","\n","    # --- Forecast (2026-02 to 2026-12) ---\n","    fcst_data = forecast_df[forecast_df['channel'] == channel][['month', 'sku', 'product_name', 'forecast_qty']].copy()\n","    fcst_data.columns = ['year_month_str', 'products__variants__sku', 'product_name', 'quantity']\n","    fcst_data['type_flag'] = 'Forecast'\n","\n","    # Combine\n","    combined = pd.concat([hist_data, fcst_data], ignore_index=True)\n","    # Pivot with two index levels: product_name and sku\n","    combined['product_name'] = combined['product_name'].fillna('')\n","    combined['products__variants__sku'] = combined['products__variants__sku'].fillna('')\n","\n","    pivot = combined.pivot_table(\n","        index=['product_name', 'products__variants__sku'],\n","        columns='year_month_str',\n","        values='quantity',\n","        fill_value=0,\n","        aggfunc='sum'\n","    )\n","\n","    # Sort columns chronologically\n","    pivot = pivot.reindex(sorted(pivot.columns), axis=1)\n","\n","    return pivot\n","\n","\n","comparison_pivots = {}\n","for channel in all_channels:\n","    comparison_pivots[channel] = build_comparison_pivot(channel, monthly_data, forecast_df, sku_details)\n","\n","print(\"‚úÖ Comparison pivots built (2024 actuals | 2025 actuals | 2026 forecast)\")\n","# Show column range for verification\n","sample_cols = list(comparison_pivots['TOTAL'].columns)\n","print(f\"Columns: {sample_cols[0]} ‚Üí {sample_cols[-1]} ({len(sample_cols)} months)\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJAHZDbvxoRw","outputId":"93750f46-d093-4031-fcb6-cbf6f204e03a","executionInfo":{"status":"ok","timestamp":1771431671323,"user_tz":480,"elapsed":46,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Summary dataframes ready\n"]}],"source":["# Create comparison DataFrames and helper structures\n","comparison_results = []\n","for channel in all_channels:\n","    channel_forecasts = forecast_df[forecast_df['channel'] == channel]\n","    total_channel_forecast = channel_forecasts['forecast_qty'].sum()\n","    product_type_forecasts = channel_forecasts.groupby('product_type')['forecast_qty'].sum().reset_index()\n","    total_by_product_type = product_type_forecasts['forecast_qty'].sum()\n","    total_by_sku = channel_forecasts.groupby('sku')['forecast_qty'].sum().sum()\n","\n","    comparison_results.append({\n","        'Channel': channel,\n","        'A - Total Forecast': round(total_channel_forecast, 0),\n","        'B - Product Type': round(total_by_product_type, 0),\n","        'C - Item Level': round(total_by_sku, 0),\n","        'B vs A Diff': round(total_by_product_type - total_channel_forecast, 2),\n","        'C vs A Diff': round(total_by_sku - total_channel_forecast, 2)\n","    })\n","\n","comparison_df = pd.DataFrame(comparison_results)\n","\n","# Product type breakdown\n","product_type_details = []\n","for channel in all_channels:\n","    channel_forecasts = forecast_df[forecast_df['channel'] == channel]\n","    pt_summary = channel_forecasts.groupby('product_type').agg(\n","        Total_Forecast_Qty=('forecast_qty', 'sum'),\n","        Num_SKUs=('sku', 'nunique')\n","    ).reset_index()\n","    pt_summary.columns = ['Product_Type', 'Total_Forecast_Qty', 'Num_SKUs']\n","    pt_summary['Channel'] = channel\n","    pt_summary['Avg_Per_SKU'] = (pt_summary['Total_Forecast_Qty'] / pt_summary['Num_SKUs']).round(1)\n","    channel_total = pt_summary['Total_Forecast_Qty'].sum()\n","    pt_summary['Pct_of_Channel'] = ((pt_summary['Total_Forecast_Qty'] / channel_total) * 100).round(1)\n","    product_type_details.append(pt_summary)\n","\n","product_type_df = pd.concat(product_type_details, ignore_index=True)\n","product_type_df = product_type_df[['Channel', 'Product_Type', 'Num_SKUs', 'Total_Forecast_Qty', 'Avg_Per_SKU', 'Pct_of_Channel']]\n","\n","# Channel summary\n","summary_by_channel = []\n","for channel in all_channels:\n","    if channel == 'TOTAL':\n","        channel_monthly = monthly_data.groupby(['year_month_str'])['quantity'].sum().reset_index()\n","    else:\n","        channel_monthly = monthly_data[monthly_data['orders__source'] == channel].groupby(['year_month_str'])['quantity'].sum().reset_index()\n","    channel_monthly['year'] = channel_monthly['year_month_str'].str[:4]\n","    yearly = channel_monthly.groupby('year')['quantity'].sum()\n","    forecast_total = forecast_df[forecast_df['channel'] == channel]['forecast_qty'].sum()\n","    summary_by_channel.append({\n","        'Channel': channel,\n","        '2022_Total': int(yearly.get('2022', 0)),\n","        '2023_Total': int(yearly.get('2023', 0)),\n","        '2024_Total': int(yearly.get('2024', 0)),\n","        '2025_Total': int(yearly.get('2025', 0)),\n","        '2026_YTD': int(yearly.get('2026', 0)),\n","        '2026_Forecast': int(forecast_total)\n","    })\n","\n","summary_df = pd.DataFrame(summary_by_channel)\n","summary_df['YoY_Growth'] = ((summary_df['2026_Forecast'] - summary_df['2025_Total']) / summary_df['2025_Total'] * 100).round(1)\n","\n","print(\"‚úÖ Summary dataframes ready\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21s6kxVixoRx","outputId":"2f35c696-47d2-49cc-8bd5-ca5db67963f4","executionInfo":{"status":"ok","timestamp":1771431689161,"user_tz":480,"elapsed":12224,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Building per-channel monthly views...\n","  DEBUG Direct-to-Consumer: act_pivot has 3404 rows, years: [np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025), np.int64(2026)]\n","  DEBUG Direct-to-Consumer: Sample 2025 rows:\n","    BLANKET-W-1INSERT: 2025-11 = 1\n","    BLANKET-W-3INSERT: 2025-02 = 1\n","    FG-10002: 2025-01 = 11\n","  DEBUG Direct-to-Consumer: FG-10103 is in skus_with_forecast\n","  DEBUG Direct-to-Consumer: FG-10103 is in all_skus (will be processed)\n","  DEBUG: First SKU FG-110001:\n","    sku_2024 rows: 8, sku_2025 rows: 11\n","    sku_2025 months: [np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12)]\n","    sku_2025 total: 25\n","\n","  DEBUG SKU FG-10103 in Direct-to-Consumer:\n","    sku_2024 rows: 0, sku_2025 rows: 0\n","    sku_2025 is EMPTY for this channel\n","  Direct-to-Consumer: 156 SKUs √ó 12 months = 1872 rows\n","  DEBUG Wholesale: act_pivot has 3740 rows, years: [np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025), np.int64(2026)]\n","  DEBUG Wholesale: Sample 2025 rows:\n","    FG-100004: 2025-01 = 7\n","    FG-100004: 2025-02 = 13\n","    FG-100004: 2025-03 = 11\n","  DEBUG Wholesale: FG-10103 is in skus_with_forecast\n","  DEBUG Wholesale: FG-10103 is in all_skus (will be processed)\n","  DEBUG: First SKU FG-110001:\n","    sku_2024 rows: 4, sku_2025 rows: 10\n","    sku_2025 months: [np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11), np.int64(12)]\n","    sku_2025 total: 18\n","\n","  DEBUG SKU FG-10103 in Wholesale:\n","    sku_2024 rows: 0, sku_2025 rows: 0\n","    sku_2025 is EMPTY for this channel\n","  Wholesale: 127 SKUs √ó 12 months = 1524 rows\n","  DEBUG TOTAL: act_pivot has 5173 rows, years: [np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025), np.int64(2026)]\n","  DEBUG TOTAL: Sample 2025 rows:\n","    BLANKET-W-1INSERT: 2025-11 = 1\n","    BLANKET-W-3INSERT: 2025-02 = 1\n","    FG-100004: 2025-01 = 7\n","  DEBUG TOTAL: FG-10103 is in skus_with_forecast\n","  DEBUG TOTAL: FG-10103 is in all_skus (will be processed)\n","  DEBUG: First SKU FG-110001:\n","    sku_2024 rows: 10, sku_2025 rows: 11\n","    sku_2025 months: [np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12)]\n","    sku_2025 total: 43\n","\n","  DEBUG SKU FG-10103 in TOTAL:\n","    sku_2024 rows: 0, sku_2025 rows: 0\n","    sku_2025 is EMPTY for this channel\n","  TOTAL: 206 SKUs √ó 12 months = 2472 rows\n","\n","Building building blocks view...\n","  Building Blocks: 3300 rows (275 active SKUs)\n","\n","‚úÖ All views ready\n"]}],"source":["# ============================================================\n","# STEP 6: BUILD AGGREGATED VIEWS ‚Äî per channel, monthly rows\n","# ============================================================\n","# Output structure per channel tab:\n","#   Product Name | SKU | Month | Year 2024 | Year 2025 | Forecast 2026\n","# Each SKU has 12 rows (one per calendar month Jan‚ÄìDec).\n","# Year 2024 / Year 2025 = sum of actuals for that month across both years.\n","# Forecast 2026 = Jan actual + Feb-Dec statistical forecast.\n","# A subtotal row is added per SKU, and a grand total at the bottom.\n","#\n","# Also builds the Building Blocks dataset:\n","#   Product Name | SKU | Month | Raw 2025 | Deseasonalized 2025 | Seasonal Index | Trend Slope | Forecast 2026\n","# ============================================================\n","\n","MONTHS = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n","\n","def col_letter(n):\n","    \"\"\"Convert 1-based column index to spreadsheet letter(s).\"\"\"\n","    result = ''\n","    while n > 0:\n","        n, remainder = divmod(n - 1, 26)\n","        result = chr(65 + remainder) + result\n","    return result\n","\n","\n","def build_channel_monthly_view(channel, monthly_data, forecast_df, sku_details):\n","    \"\"\"\n","    Returns a list of row dicts with columns:\n","      Product Name, SKU, Product_Type, Month (1-12), Month_Name,\n","      Year_2024, Year_2025, Forecast_2026\n","    One row per SKU per calendar month. Only SKUs with any data included.\n","    \"\"\"\n","    # --- actuals ---\n","    if channel == 'TOTAL':\n","        act = monthly_data.groupby(['year_month_str','products__variants__sku'])['quantity'].sum().reset_index()\n","    else:\n","        act = monthly_data[monthly_data['orders__source'] == channel][\n","            ['year_month_str','products__variants__sku','quantity']].copy()\n","\n","    act = act.merge(sku_details[['products__variants__sku','product_name','products__product_type']],\n","                    on='products__variants__sku', how='left')\n","    act['year']  = act['year_month_str'].str[:4].astype(int)\n","    act['month'] = act['year_month_str'].str[5:7].astype(int)\n","\n","    # sum actuals by SKU + year + calendar month\n","    act_pivot = act.groupby(['products__variants__sku','product_name','products__product_type','year','month'])[\n","        'quantity'].sum().reset_index()\n","\n","    # DEBUG: Check what years are in act_pivot\n","    if len(act_pivot) > 0:\n","        years_in_pivot = sorted(act_pivot['year'].unique())\n","        print(f\"  DEBUG {channel}: act_pivot has {len(act_pivot)} rows, years: {years_in_pivot}\")\n","        # Show sample for a SKU with 2025 data\n","        sample_2025 = act_pivot[act_pivot['year'] == 2025].head(3)\n","        if len(sample_2025) > 0:\n","            print(f\"  DEBUG {channel}: Sample 2025 rows:\")\n","            for _, row in sample_2025.iterrows():\n","                print(f\"    {row['products__variants__sku']}: {row['year']}-{row['month']:02d} = {row['quantity']}\")\n","    else:\n","        print(f\"  DEBUG {channel}: WARNING - act_pivot is EMPTY!\")\n","\n","    # --- forecasts (Feb-Dec 2026) ---\n","    fcst = forecast_df[forecast_df['channel'] == channel][\n","        ['sku','product_name','product_type','month','forecast_qty']].copy()\n","    fcst['month_num'] = fcst['month'].str[5:7].astype(int)\n","\n","    # --- build rows ---\n","    rows = []\n","    # Iterate over SKUs that have EITHER historical data OR forecast data\n","    skus_with_actuals = set(act_pivot['products__variants__sku'].unique())\n","    skus_with_forecast = set(fcst['sku'].unique())\n","    all_skus = list(skus_with_actuals | skus_with_forecast)\n","\n","    # DEBUG: Check if FG-10103 is in the lists\n","    if \"FG-10103\" in skus_with_actuals:\n","        print(f\"  DEBUG {channel}: FG-10103 is in skus_with_actuals\")\n","    if \"FG-10103\" in skus_with_forecast:\n","        print(f\"  DEBUG {channel}: FG-10103 is in skus_with_forecast\")\n","    if \"FG-10103\" in all_skus:\n","        print(f\"  DEBUG {channel}: FG-10103 is in all_skus (will be processed)\")\n","    else:\n","        print(f\"  DEBUG {channel}: FG-10103 is NOT in all_skus (will be skipped!)\")\n","\n","    for sku in all_skus:\n","        sku_info = sku_details[sku_details['products__variants__sku'] == sku]\n","        if len(sku_info) == 0:\n","            continue\n","        sku_info = sku_info.iloc[0]\n","        prod_name  = sku_info['product_name']\n","        prod_type  = sku_info['products__product_type']\n","\n","        sku_act  = act_pivot[act_pivot['products__variants__sku'] == sku]\n","        sku_fcst = fcst[fcst['sku'] == sku]\n","\n","        # Check if this SKU has any data for this channel at all\n","        # Use .isin() to handle both int and np.int64 types\n","        sku_2024 = sku_act[sku_act['year'].isin([2024])]\n","        sku_2025 = sku_act[sku_act['year'].isin([2025])]\n","        sku_2026_jan = sku_act[(sku_act['year'].isin([2026])) & (sku_act['month'].isin([1]))]\n","        has_data = (len(sku_2024) + len(sku_2025) + len(sku_2026_jan) + len(sku_fcst)) > 0\n","        if not has_data:\n","            continue\n","\n","        # DEBUG: Show what we have for the first SKU only\n","        if sku == list(all_skus)[0]:\n","            print(f\"  DEBUG: First SKU {sku}:\")\n","            print(f\"    sku_2024 rows: {len(sku_2024)}, sku_2025 rows: {len(sku_2025)}\")\n","            if len(sku_2025) > 0:\n","                print(f\"    sku_2025 months: {sorted(sku_2025[\"month\"].unique())}\")\n","                print(f\"    sku_2025 total: {sku_2025[\"quantity\"].sum()}\")\n","\n","        for m in range(1, 13):\n","            val_2024 = int(sku_2024[sku_2024['month'] == m]['quantity'].sum())\n","            val_2025 = int(sku_2025[sku_2025['month'] == m]['quantity'].sum())\n","\n","            # DEBUG: Active debug for FG-10103\n","            if sku == \"FG-10103\":\n","                if m == 1:  # Only print once per SKU\n","                    print(f\"\\n  DEBUG SKU {sku} in {channel}:\")\n","                    print(f\"    sku_2024 rows: {len(sku_2024)}, sku_2025 rows: {len(sku_2025)}\")\n","                    if len(sku_2025) > 0:\n","                        print(f\"    sku_2025 months available: {sorted(sku_2025[\"month\"].unique())}\")\n","                        print(f\"    sku_2025 total quantity: {sku_2025[\"quantity\"].sum()}\")\n","                    else:\n","                        print(f\"    sku_2025 is EMPTY for this channel\")\n","                if val_2025 == 0 and len(sku_2025) > 0:\n","                    print(f\"    Month {m}: val_2025=0 BUT sku_2025 has {len(sku_2025)} rows!\")\n","\n","            # 2026: Jan = actual, Feb-Dec = forecast\n","            if m == 1:\n","                val_2026 = int(sku_2026_jan['quantity'].sum()) if len(sku_2026_jan) > 0 else 0\n","            else:\n","                match = sku_fcst[sku_fcst['month_num'] == m]\n","                val_2026 = int(match['forecast_qty'].sum()) if len(match) > 0 else 0\n","\n","            is_active = sku in active_skus_from_file\n","\n","            rows.append({\n","                'Product Name': prod_name,\n","                'SKU': sku,\n","                'Product_Type': prod_type,\n","                'Is_Active': 'Yes' if is_active else 'No',\n","                'Month': m,\n","                'Month_Name': MONTHS[m-1],\n","                'Year_2024': val_2024,\n","                'Year_2025': val_2025,\n","                'Forecast_2026': val_2026,\n","            })\n","\n","    return pd.DataFrame(rows)\n","\n","\n","def build_building_blocks(monthly_data, forecast_df, sku_details, pt_seasonal_indices, channel_growth_rates=None):\n","    \"\"\"\n","    For each active SKU, for each calendar month, shows:\n","      Product Name | SKU | Product_Type | Month | Month_Name |\n","      Raw_2025 | Seasonal_Index | Deseasonalized_2025 |\n","      Trend_Slope_Per_Month | Base_Level | Forecast_2026\n","    \"\"\"\n","    # TOTAL channel actuals\n","    act = monthly_data.groupby(['year_month_str','products__variants__sku'])['quantity'].sum().reset_index()\n","    act['year']  = act['year_month_str'].str[:4].astype(int)\n","    act['month'] = act['year_month_str'].str[5:7].astype(int)\n","    act_2025 = act[act['year'] == 2025].copy()\n","\n","    # forecasts (TOTAL channel)\n","    fcst = forecast_df[forecast_df['channel'] == 'TOTAL'][\n","        ['sku','month','forecast_qty']].copy()\n","    fcst['month_num'] = fcst['month'].str[5:7].astype(int)\n","\n","    if channel_growth_rates is None:\n","        channel_growth_rates = {}\n","\n","    rows = []\n","    for sku in sku_details['products__variants__sku'].unique():\n","\n","        sku_info = sku_details[sku_details['products__variants__sku'] == sku]\n","        if len(sku_info) == 0:\n","            continue\n","        sku_info  = sku_info.iloc[0]\n","        prod_name = sku_info['product_name']\n","        prod_type = sku_info['products__product_type']\n","        seas_idx  = pt_seasonal_indices.get(prod_type, {m: 1.0 for m in range(1,13)})\n","\n","        # Get historical values for trend/base calculation (same as forecast engine)\n","        sku_hist = act[(act['products__variants__sku'] == sku) &\n","                       (act['year_month_str'] <= '2026-01')].sort_values('year_month_str')\n","        hist_vals  = sku_hist['quantity'].values.astype(float)\n","        hist_months = np.array([int(ym[5:7]) for ym in sku_hist['year_month_str'].values])\n","\n","        n = len(hist_vals)\n","        window = min(n, 12)\n","        if window >= 4:\n","            recent_vals   = hist_vals[-window:]\n","            recent_months = hist_months[-window:]\n","            deseason_recent = np.array([\n","                v / seas_idx.get(int(m), 1.0) if seas_idx.get(int(m), 1.0) > 0 else v\n","                for v, m in zip(recent_vals, recent_months)\n","            ])\n","            # exponential weighted base\n","            alpha = 0.15\n","            wts = np.array([(1 - alpha)**(window - 1 - i) for i in range(window)])\n","            base_level  = float(np.dot(wts, deseason_recent) / wts.sum())\n","            # weighted trend slope\n","            weights = np.arange(1, window + 1, dtype=float)\n","            x = np.arange(window, dtype=float)\n","            wsum = weights.sum(); wx = (weights*x).sum(); wy = (weights*deseason_recent).sum()\n","            wxx = (weights*x*x).sum(); wxy = (weights*x*deseason_recent).sum()\n","            denom = wsum*wxx - wx*wx\n","            trend_slope = float((wsum*wxy - wx*wy) / denom) if abs(denom) > 1e-10 else 0.0\n","            max_slope = base_level * 0.025 if base_level > 0 else 1.0\n","            trend_slope = float(np.clip(trend_slope, -max_slope, max_slope))\n","        else:\n","            base_level  = float(np.mean(hist_vals)) if n > 0 else 0.0\n","            trend_slope = 0.0\n","\n","        sku_2025_act = act_2025[act_2025['products__variants__sku'] == sku]\n","        sku_fcst     = fcst[fcst['sku'] == sku]\n","\n","        for m in range(1, 13):\n","            raw_2025 = int(sku_2025_act[sku_2025_act['month'] == m]['quantity'].sum())\n","            si = round(seas_idx.get(m, 1.0), 4)\n","            deseas_2025 = round(raw_2025 / si, 1) if si > 0 else raw_2025\n","\n","            match = sku_fcst[sku_fcst['month_num'] == m]\n","            fcst_2026 = int(match['forecast_qty'].sum()) if len(match) > 0 else 0\n","            if m == 1:\n","                jan_act = act[(act['products__variants__sku'] == sku) &\n","                              (act['year'] == 2026) & (act['month'] == 1)]['quantity'].sum()\n","                fcst_2026 = int(jan_act)\n","\n","            rows.append({\n","                'Product Name': prod_name,\n","                'SKU': sku,\n","                'Product_Type': prod_type,\n","                'Month': m,\n","                'Month_Name': MONTHS[m-1],\n","                'Raw_2025_Actual': raw_2025,\n","                'Seasonal_Index': si,\n","                'Deseasonalized_2025': deseas_2025,\n","                'Base_Level_(deseason)': round(base_level, 1),\n","                'Trend_Slope_(units/mo)': round(trend_slope, 4),\n","                'Growth_Rate_Override': {ch: f'{r*100:+.1f}%' for ch, r in channel_growth_rates.items()}.get('TOTAL', '+0.0%'),\n","                'DTC_Growth_Override':  f\"{channel_growth_rates.get('Direct-to-Consumer', 0.0)*100:+.1f}%\",\n","                'Wholesale_Growth_Override': f\"{channel_growth_rates.get('Wholesale', 0.0)*100:+.1f}%\",\n","                'Total_Growth_Override': f\"{channel_growth_rates.get('TOTAL', 0.0)*100:+.1f}%\",\n","                'Forecast_2026': fcst_2026,\n","            })\n","\n","    return pd.DataFrame(rows)\n","\n","\n","# Build all views\n","print(\"Building per-channel monthly views...\")\n","channel_monthly_views = {}\n","for ch in all_channels:\n","    channel_monthly_views[ch] = build_channel_monthly_view(\n","        ch, monthly_data, forecast_df, sku_details)\n","    n_skus = channel_monthly_views[ch]['SKU'].nunique()\n","    print(f\"  {ch}: {n_skus} SKUs √ó 12 months = {len(channel_monthly_views[ch])} rows\")\n","\n","print(\"\\nBuilding building blocks view...\")\n","building_blocks_df = build_building_blocks(\n","    monthly_data, forecast_df, sku_details, pt_seasonal_indices,\n","    channel_growth_rates=CHANNEL_GROWTH_RATES)\n","print(f\"  Building Blocks: {len(building_blocks_df)} rows ({building_blocks_df['SKU'].nunique()} active SKUs)\")\n","print(\"\\n‚úÖ All views ready\")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCgtLvVtxoRx","outputId":"0d0dcd60-caa9-47f8-800a-e5297fef4d34","executionInfo":{"status":"ok","timestamp":1771431746933,"user_tz":480,"elapsed":14467,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Authenticating with Google...\n","‚úÖ Authenticated\n"]}],"source":["# Authenticate with Google and create new Google Sheet\n","import gspread\n","from google.colab import auth\n","from google.auth import default\n","\n","print(\"Authenticating with Google...\")\n","auth.authenticate_user()\n","creds, _ = default()\n","gc = gspread.authorize(creds)\n","print(\"‚úÖ Authenticated\")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ObOMT5P0xoRx","outputId":"542df7f9-31f5-43c5-a22a-1df36cb093bd","executionInfo":{"status":"ok","timestamp":1771431750976,"user_tz":480,"elapsed":1904,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Created Google Sheet: Demand_Planning_20260218_1622\n","URL: https://docs.google.com/spreadsheets/d/18330-VAQg6Cd-kWFujImQ8agIyUwqH_qWRzb6_obE6k\n"]}],"source":["# Create new Google Sheet\n","sheet_name = f\"Demand_Planning_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n","sh = gc.create(sheet_name)\n","print(f\"Created Google Sheet: {sheet_name}\")\n","print(f\"URL: https://docs.google.com/spreadsheets/d/{sh.id}\")"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0mWRIYBKxoRx","outputId":"1da3d918-88ad-4f9f-eded-963cdbf14846","executionInfo":{"status":"ok","timestamp":1771431758578,"user_tz":480,"elapsed":4436,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Summary Dashboard created with full methodology explanation\n"]}],"source":["# ============================================================\n","# WRITE: Summary Dashboard\n","# ============================================================\n","summary_sheet = sh.sheet1\n","summary_sheet.update_title('Summary Dashboard')\n","\n","summary_sheet.update('A1', [['DEMAND PLANNING SUMMARY']])\n","summary_sheet.update('A3', [['Historical Period: 2022-01 through 2026-01']])\n","summary_sheet.update('A4', [['Forecast Period: 2026-02 through 2026-12']])\n","\n","# --- Methodology explanation ---\n","method_rows = [\n","    ['FORECASTING METHODOLOGY'],\n","    [''],\n","    ['SEASONALITY (Product-Type Level)'],\n","    ['  Seasonal indices are calculated by pooling all SKUs within each product type together, using the last 24 months'],\n","    ['  of TOTAL channel sales data. For each calendar month (Jan‚ÄìDec), we compute the average volume relative to the'],\n","    ['  overall monthly average for that product type. This produces a stable index (e.g. 1.42 = 42% above average,'],\n","    ['  0.71 = 29% below average) that is shared by all SKUs in the same product type. Using product-type pooling'],\n","    ['  rather than per-item indices prevents noisy, low-volume SKUs from generating unreliable seasonal patterns.'],\n","    [''],\n","    ['TREND (Per-SKU, Recency-Weighted)'],\n","    ['  A linear trend is estimated for each SKU individually using the last 12 months of deseasonalized sales.'],\n","    ['  Weighted least-squares regression is used, where the most recent month carries 12x the weight of the'],\n","    ['  oldest month in the window. This means recent acceleration or deceleration in demand has a much stronger'],\n","    ['  influence on the slope than older data. The trend slope is capped at ¬±2.5% of the base level per month'],\n","    ['  (~30% annually) to prevent runaway projections on sparse or erratic SKUs.'],\n","    [''],\n","    ['BASE LEVEL (Per-SKU)'],\n","    ['  The deseasonalized base level is calculated as an exponentially weighted moving average of the last 12'],\n","    ['  months (decay factor alpha=0.15). Recent months carry significantly more weight than older months,'],\n","    ['  so the base level responds to recent demand shifts while remaining stable against one-off spikes.'],\n","    [''],\n","    ['FORECAST CALCULATION'],\n","    ['  For each future month: Forecast = (Base Level + Trend √ó Steps Ahead) √ó Seasonal Index √ó Growth Factor'],\n","    ['  Seasonal Index: product-type index for that calendar month'],\n","    ['  Growth Factor: optional manual override (default 0% = pure statistical forecast)'],\n","    ['  All forecasts are rounded to whole units ‚Äî no fractional quantities.'],\n","    [''],\n","    ['INACTIVITY RULE'],\n","    ['  Any SKU with zero total sales across all channels in the 6-month window prior to the forecast start'],\n","    ['  is classified as inactive and receives no forecast. These SKUs still appear in historical views.'],\n","    [''],\n","    ['WHAT THIS FORECAST DOES NOT CAPTURE'],\n","    ['  The statistical model extrapolates demand patterns from historical sell-through data. It does not'],\n","    ['  account for the following factors, which should be applied as manual judgment on top of the forecast:'],\n","    ['  ‚Ä¢ Promotions & Discounts: Heavy discounting (e.g. sitewide sales) inflates historical volume in'],\n","    ['    those months. The model will partially absorb this into the base level and seasonal index,'],\n","    ['    which can cause future months to be over- or under-forecast relative to promo intent.'],\n","    ['  ‚Ä¢ New Product Launches: SKUs with < 6 months of history have limited trend signal. Review'],\n","    ['    their forecasts manually and consider applying a growth override.'],\n","    ['  ‚Ä¢ Planned Price Changes: A price increase typically suppresses volume; a reduction lifts it.'],\n","    ['    Neither is visible to the model.'],\n","    ['  ‚Ä¢ Inventory / Supply Constraints: Stockouts in the historical window appear as zero demand,'],\n","    ['    causing the model to underestimate true underlying demand for those periods.'],\n","    ['  ‚Ä¢ Channel Mix Shifts: If volume is intentionally being moved between DTC and Wholesale,'],\n","    ['    the channel-level forecasts will not reflect that intent.'],\n","    ['  ‚Ä¢ Discontinued SKUs: Captured by the inactivity rule but only if sales went to zero in the'],\n","    ['    last 6 months. SKUs being wound down gradually will still receive a (likely too-high) forecast.'],\n","    [''],\n","]\n","summary_sheet.update('A6', method_rows)\n","\n","method_end_row = 6 + len(method_rows) + 1\n","summary_sheet.update(f'A{method_end_row}', [['CHANNEL SUMMARY']])\n","summary_data = [summary_df.columns.tolist()] + summary_df.values.tolist()\n","summary_sheet.update(f'A{method_end_row + 2}', summary_data)\n","\n","comparison_start = method_end_row + 12\n","summary_sheet.update(f'A{comparison_start}', [['FORECAST AGGREGATION COMPARISON']])\n","comparison_data = [comparison_df.columns.tolist()] + comparison_df.values.tolist()\n","summary_sheet.update(f'A{comparison_start + 2}', comparison_data)\n","\n","summary_sheet.format('A1', {'textFormat': {'bold': True, 'fontSize': 14}})\n","summary_sheet.format('A6', {'textFormat': {'bold': True, 'fontSize': 12}})\n","summary_sheet.format('A8', {'textFormat': {'bold': True, 'underline': True}})\n","summary_sheet.format('A14', {'textFormat': {'bold': True, 'underline': True}})\n","summary_sheet.format('A21', {'textFormat': {'bold': True, 'underline': True}})\n","summary_sheet.format('A27', {'textFormat': {'bold': True, 'underline': True}})\n","summary_sheet.format('A33', {'textFormat': {'bold': True, 'underline': True}})\n","summary_sheet.format(f'A{method_end_row}', {'textFormat': {'bold': True, 'fontSize': 12}})\n","summary_sheet.format(f'A{method_end_row + 2}:H{method_end_row + 2}', {\n","    'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","    'backgroundColor': {'red': 0.259, 'green': 0.522, 'blue': 0.957}\n","})\n","summary_sheet.format(f'A{comparison_start}', {'textFormat': {'bold': True, 'fontSize': 12}})\n","summary_sheet.format(f'A{comparison_start + 2}:F{comparison_start + 2}', {\n","    'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","    'backgroundColor': {'red': 0.259, 'green': 0.522, 'blue': 0.957}\n","})\n","\n","print(\"Summary Dashboard created with full methodology explanation\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndSbeP8uxoRx","outputId":"f1482a5e-3781-4619-f78f-bc74dbdff2eb","executionInfo":{"status":"ok","timestamp":1771431764402,"user_tz":480,"elapsed":1650,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Product Type Breakdown sheet created (with seasonality indices)\n"]}],"source":["# ============================================================\n","# WRITE: Product Type Breakdown (with Seasonality Table)\n","# ============================================================\n","pt_sheet = sh.add_worksheet(title='Product Type Breakdown', rows=1000, cols=30)\n","\n","# Section 1: Seasonality indices\n","pt_sheet.update('A1', [['SEASONAL INDICES BY PRODUCT TYPE AND MONTH']])\n","pt_sheet.update('A2', [['Based on last 24 months of TOTAL channel data. Index > 1.0 = stronger than average. Normalized so each row averages to 1.0.']])\n","\n","seas_data = [seasonality_display_df.columns.tolist()] + seasonality_display_df.values.tolist()\n","pt_sheet.update('A4', seas_data)\n","\n","# Header formatting for seasonality table\n","pt_sheet.format('A1', {'textFormat': {'bold': True, 'fontSize': 13}})\n","num_pt_rows = len(seasonality_display_df)\n","header_range = f'A4:M4'\n","pt_sheet.format(header_range, {\n","    'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","    'backgroundColor': {'red': 0.18, 'green': 0.53, 'blue': 0.33}  # green\n","})\n","\n","# Section 2: Forecast summary by product type\n","sep_row = num_pt_rows + 7  # leave a gap\n","pt_sheet.update(f'A{sep_row}', [['FORECAST SUMMARY BY PRODUCT TYPE AND CHANNEL']])\n","pt_sheet.format(f'A{sep_row}', {'textFormat': {'bold': True, 'fontSize': 13}})\n","\n","pt_data = [product_type_df.columns.tolist()] + product_type_df.values.tolist()\n","pt_sheet.update(f'A{sep_row + 2}', pt_data)\n","pt_sheet.format(f'A{sep_row + 2}:F{sep_row + 2}', {\n","    'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","    'backgroundColor': {'red': 0.259, 'green': 0.522, 'blue': 0.957}\n","})\n","\n","print(\"Product Type Breakdown sheet created (with seasonality indices)\")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVxhp5AnxoRx","outputId":"2e46bb25-be5c-44d6-e146-7e5833346b19","executionInfo":{"status":"ok","timestamp":1771431773926,"user_tz":480,"elapsed":7659,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating forecast sheet for Direct-to-Consumer...\n","  ‚Üí 36 months (25 actuals + 11 forecast)\n","Creating forecast sheet for Wholesale...\n","  ‚Üí 36 months (25 actuals + 11 forecast)\n","Creating forecast sheet for TOTAL...\n","  ‚Üí 36 months (25 actuals + 11 forecast)\n","\n","All channel forecast sheets created\n"]}],"source":["# ============================================================\n","# WRITE: Channel Forecast + Comparison Pivot sheets\n","# Each channel gets ONE sheet: 2024 actuals | 2025 actuals | 2026 (Jan actual + Feb-Dec forecast)\n","# ============================================================\n","\n","FORECAST_START = '2026-02'  # first forecast month\n","\n","for channel in all_channels:\n","    print(f\"Creating forecast sheet for {channel}...\")\n","\n","    ws = sh.add_worksheet(title=f\"{channel} - Forecast\", rows=2000, cols=150)\n","\n","    pivot = comparison_pivots[channel]\n","    all_cols = list(pivot.columns)  # chronologically sorted month strings\n","\n","    # Identify which columns are forecast vs actual\n","    # 2026-01 = actual, 2026-02 onward = forecast\n","    actual_cols = [c for c in all_cols if c < FORECAST_START]\n","    forecast_cols = [c for c in all_cols if c >= FORECAST_START]\n","\n","    # Build header rows\n","    # Row 1: title\n","    ws.update('A1', [[f'{channel} ‚Äî Historical vs Forecast']])\n","\n","    # Row 2: year group labels  (2024 actuals / 2025 actuals / 2026 actual+forecast)\n","    year_label_row = ['Product Name', 'SKU']\n","    prev_year = None\n","    col_labels = []\n","    for c in all_cols:\n","        yr = c[:4]\n","        is_fcst = (c >= FORECAST_START)\n","        label = f\"{yr} {'[FORECAST]' if is_fcst else '[ACTUAL]'}\"\n","        col_labels.append(label)\n","    year_label_row = ['Product Name', 'SKU'] + col_labels\n","\n","    # Row 3: month column headers\n","    month_header_row = ['Product Name', 'SKU'] + all_cols\n","\n","    # Data rows ‚Äî MultiIndex: (product_name, sku)\n","    data_rows = []\n","    for idx in pivot.index:\n","        prod_name, sku_code = idx\n","        row = [prod_name, sku_code] + [int(round(pivot.loc[idx, c])) if c in pivot.columns else 0 for c in all_cols]\n","        data_rows.append(row)\n","\n","    # Add a TOTALS row\n","    totals_row_data = ['** CHANNEL TOTAL **', '']\n","    for c in all_cols:\n","        if c in pivot.columns:\n","            totals_row_data.append(int(round(pivot[c].sum())))\n","        else:\n","            totals_row_data.append(0)\n","    data_rows.append(totals_row_data)\n","\n","    ws.update('A2', [year_label_row])\n","    ws.update('A3', [month_header_row])\n","    ws.update('A4', data_rows)\n","\n","    # Format headers\n","    ws.format('A1', {'textFormat': {'bold': True, 'fontSize': 13}})\n","\n","    # Row 2: alternating year/type shading\n","    # Row 3: column month headers ‚Äî bold\n","    ws.format('A3', {'textFormat': {'bold': True}})\n","\n","    # Color the actual columns header (row 2) in grey-blue\n","    num_actual = len(actual_cols)\n","    num_forecast = len(forecast_cols)\n","\n","    if num_actual > 0:\n","        # Columns B onward for actual (1-indexed ‚Üí col B = 2)\n","        import string\n","        def col_letter(n):\n","            \"\"\"Convert 1-based column index to letter(s).\"\"\"\n","            result = ''\n","            while n > 0:\n","                n, remainder = divmod(n - 1, 26)\n","                result = chr(65 + remainder) + result\n","            return result\n","\n","        actual_start_col = col_letter(2)  # B\n","        actual_end_col = col_letter(1 + num_actual)\n","        ws.format(f'{actual_start_col}2:{actual_end_col}2', {\n","            'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","            'backgroundColor': {'red': 0.36, 'green': 0.44, 'blue': 0.56}  # slate\n","        })\n","        ws.format(f'{actual_start_col}3:{actual_end_col}3', {\n","            'textFormat': {'bold': True}\n","        })\n","\n","    if num_forecast > 0:\n","        fcst_start_col = col_letter(2 + num_actual)\n","        fcst_end_col = col_letter(1 + num_actual + num_forecast)\n","        ws.format(f'{fcst_start_col}2:{fcst_end_col}2', {\n","            'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","            'backgroundColor': {'red': 0.18, 'green': 0.53, 'blue': 0.33}  # green for forecast\n","        })\n","        ws.format(f'{fcst_start_col}3:{fcst_end_col}3', {\n","            'textFormat': {'bold': True, 'foregroundColor': {'red': 0.1, 'green': 0.5, 'blue': 0.2}}\n","        })\n","\n","    print(f\"  ‚Üí {len(all_cols)} months ({num_actual} actuals + {num_forecast} forecast)\")\n","\n","print(\"\\nAll channel forecast sheets created\")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhTynO_8xoRx","outputId":"a4e269f9-4618-4e5b-b26f-32718c6b1a2a","executionInfo":{"status":"ok","timestamp":1771431793241,"user_tz":480,"elapsed":9142,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing Aggregated By Channel sheets...\n","\n","  DEBUG Direct-to-Consumer dataframe check:\n","    Sample SKU: FG-110001\n","    Year_2024 total: 22\n","    Year_2025 total: 25\n","    Year_2025 sample values: [0, 4, 1]\n","\n","  DEBUG Wholesale dataframe check:\n","    Sample SKU: FG-110001\n","    Year_2024 total: 5\n","    Year_2025 total: 18\n","    Year_2025 sample values: [0, 1, 1]\n","\n","  DEBUG TOTAL dataframe check:\n","    Sample SKU: FG-110001\n","    Year_2024 total: 27\n","    Year_2025 total: 43\n","    Year_2025 sample values: [0, 5, 2]\n","  ‚úÖ Agg by Month ‚Äî Direct-to-Consumer: 2186 rows written\n","  ‚úÖ Agg by Month ‚Äî Wholesale: 1780 rows written\n","  ‚úÖ Agg by Month ‚Äî TOTAL: 2886 rows written\n","\n","Writing Building Blocks sheet...\n","  ‚úÖ Building Blocks: 3576 rows written\n","\n","‚úÖ All aggregated sheets created\n"]}],"source":["# ============================================================\n","# WRITE: Aggregated By Channel (3 tabs) + Building Blocks\n","# ============================================================\n","\n","def write_channel_agg_sheet(sh, title, df):\n","    \"\"\"\n","    Write a channel aggregated sheet.\n","    Layout: Product Name | SKU | Month | Year 2024 | Year 2025 | Forecast 2026\n","    Each SKU spans 12 rows (one per month) followed by a subtotal row.\n","    Grand total at the bottom.\n","    \"\"\"\n","    ws = sh.add_worksheet(title=title, rows=5000, cols=10)\n","\n","    header = ['Product Name', 'SKU', 'Product Type', 'Is Active', 'Month', 'Year 2024', 'Year 2025', 'Forecast 2026']\n","    data_rows = [header]\n","\n","    skus_in_order = df['SKU'].unique()\n","    grand = {'Year_2024': 0, 'Year_2025': 0, 'Forecast_2026': 0}\n","\n","    for sku in skus_in_order:\n","        sku_df = df[df['SKU'] == sku].sort_values('Month')\n","        prod_name = sku_df['Product Name'].iloc[0]\n","        prod_type = str(sku_df['Product_Type'].iloc[0]) if pd.notna(sku_df['Product_Type'].iloc[0]) else ''\n","        is_active = sku_df['Is_Active'].iloc[0]\n","        tot_2024 = sku_df['Year_2024'].sum()\n","        tot_2025 = sku_df['Year_2025'].sum()\n","        tot_2026 = sku_df['Forecast_2026'].sum()\n","\n","        for _, row in sku_df.iterrows():\n","            data_rows.append([\n","                prod_name, sku, prod_type, is_active,\n","                row['Month_Name'],\n","                row['Year_2024'], row['Year_2025'], row['Forecast_2026']\n","            ])\n","\n","        # Subtotal row for this SKU\n","        data_rows.append([prod_name + ' ‚Äî TOTAL', sku, prod_type, is_active, 'ANNUAL',\n","                          int(tot_2024), int(tot_2025), int(tot_2026)])\n","        data_rows.append(['', '', '', '', '', '', '', ''])  # spacer\n","\n","        grand['Year_2024']     += tot_2024\n","        grand['Year_2025']     += tot_2025\n","        grand['Forecast_2026'] += tot_2026\n","\n","    # Grand total\n","    data_rows.append(['** GRAND TOTAL **', '', '', '', '',\n","                      int(grand[\"Year_2024\"]), int(grand[\"Year_2025\"]), int(grand[\"Forecast_2026\"])])\n","\n","    ws.update('A1', data_rows)\n","\n","    # Formatting\n","    num_rows = len(data_rows)\n","    ws.format('A1:H1', {\n","        'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","        'backgroundColor': {'red': 0.259, 'green': 0.522, 'blue': 0.957}\n","    })\n","    ws.format(f'A{num_rows}:H{num_rows}', {\n","        'textFormat': {'bold': True},\n","        'backgroundColor': {'red': 0.95, 'green': 0.95, 'blue': 0.75}\n","    })\n","\n","    # Color Year 2024 header grey, Year 2025 slate, Forecast 2026 green\n","    ws.format('F1', {'backgroundColor': {'red': 0.75, 'green': 0.75, 'blue': 0.75}})\n","    ws.format('G1', {'backgroundColor': {'red': 0.36, 'green': 0.44, 'blue': 0.56},\n","                     'textFormat': {'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}, 'bold': True}})\n","    ws.format('H1', {'backgroundColor': {'red': 0.18, 'green': 0.53, 'blue': 0.33},\n","                     'textFormat': {'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}, 'bold': True}})\n","\n","    print(f\"  ‚úÖ {title}: {len(data_rows)} rows written\")\n","    return ws\n","\n","\n","def write_building_blocks_sheet(sh, df):\n","    \"\"\"\n","    Write the Building Blocks sheet showing deseasonalization components.\n","    Columns: Product Name | SKU | Product Type | Month | Month_Name |\n","             Raw 2025 Actual | Seasonal Index | Deseasonalized 2025 |\n","             Base Level | Trend Slope/Month | Forecast 2026\n","    \"\"\"\n","    ws = sh.add_worksheet(title='Building Blocks', rows=5000, cols=15)\n","\n","    header = [\n","        'Product Name', 'SKU', 'Product Type', 'Month #', 'Month',\n","        'Raw 2025 Actual', 'Seasonal Index', 'Deseasonalized 2025',\n","        'Base Level (deseason)', 'Trend Slope (units/mo)',\n","        'DTC Growth Override', 'Wholesale Growth Override', 'Total Growth Override',\n","        'Forecast 2026'\n","    ]\n","\n","    data_rows = [header]\n","    skus = df['SKU'].unique()\n","\n","    for sku in skus:\n","        sku_df = df[df['SKU'] == sku].sort_values('Month')\n","        prod_name = sku_df['Product Name'].iloc[0]\n","        prod_type = str(sku_df['Product_Type'].iloc[0]) if pd.notna(sku_df['Product_Type'].iloc[0]) else ''\n","\n","        for _, row in sku_df.iterrows():\n","            data_rows.append([\n","                prod_name, sku, prod_type,\n","                int(row['Month']), row['Month_Name'],\n","                row['Raw_2025_Actual'],\n","                row['Seasonal_Index'],\n","                row['Deseasonalized_2025'],\n","                row['Base_Level_(deseason)'],\n","                row['Trend_Slope_(units/mo)'],\n","                row['DTC_Growth_Override'],\n","                row['Wholesale_Growth_Override'],\n","                row['Total_Growth_Override'],\n","                row['Forecast_2026'],\n","            ])\n","        data_rows.append(['', '', '', '', '', '', '', '', '', '', ''])  # spacer\n","\n","    ws.update('A1', data_rows)\n","\n","    ws.format('A1:N1', {\n","        'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","        'backgroundColor': {'red': 0.18, 'green': 0.33, 'blue': 0.53}  # deep blue\n","    })\n","    # Colour the three building-block columns differently\n","    ws.format('F1', {'backgroundColor': {'red': 0.36, 'green': 0.44, 'blue': 0.56}})  # raw = slate\n","    ws.format('G1', {'backgroundColor': {'red': 0.60, 'green': 0.40, 'blue': 0.70}})  # index = purple\n","    ws.format('H1', {'backgroundColor': {'red': 0.60, 'green': 0.40, 'blue': 0.70}})  # deseas = purple\n","    ws.format('I1', {'backgroundColor': {'red': 0.85, 'green': 0.65, 'blue': 0.13}})  # base = amber\n","    ws.format('J1', {'backgroundColor': {'red': 0.85, 'green': 0.65, 'blue': 0.13}})  # trend = amber\n","    ws.format('K1:M1', {\n","        'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","        'backgroundColor': {'red': 0.82, 'green': 0.35, 'blue': 0.20}  # burnt orange = override\n","    })\n","    ws.format('N1', {'backgroundColor': {'red': 0.18, 'green': 0.53, 'blue': 0.33}})  # forecast = green\n","\n","    print(f\"  ‚úÖ Building Blocks: {len(data_rows)} rows written\")\n","    return ws\n","\n","\n","# Write the three channel tabs\n","print(\"Writing Aggregated By Channel sheets...\")\n","\n","# DEBUG: Check what's in the dataframes before writing\n","for ch in all_channels:\n","    df_check = channel_monthly_views[ch]\n","    if len(df_check) > 0:\n","        # Check a specific SKU that should have 2025 data\n","        sample_sku = df_check[\"SKU\"].iloc[0]\n","        sample_data = df_check[df_check[\"SKU\"] == sample_sku]\n","        year_2025_sum = sample_data[\"Year_2025\"].sum()\n","        year_2024_sum = sample_data[\"Year_2024\"].sum()\n","        print(f\"\\n  DEBUG {ch} dataframe check:\")\n","        print(f\"    Sample SKU: {sample_sku}\")\n","        print(f\"    Year_2024 total: {year_2024_sum}\")\n","        print(f\"    Year_2025 total: {year_2025_sum}\")\n","        print(f\"    Year_2025 sample values: {sample_data[\"Year_2025\"].head(3).tolist()}\")\n","\n","for ch in all_channels:\n","    write_channel_agg_sheet(sh, f\"Agg by Month ‚Äî {ch}\", channel_monthly_views[ch])\n","\n","# Write Building Blocks tab\n","print(\"\\nWriting Building Blocks sheet...\")\n","write_building_blocks_sheet(sh, building_blocks_df)\n","\n","print(\"\\n‚úÖ All aggregated sheets created\")\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"efp0NGCeYX7u","executionInfo":{"status":"ok","timestamp":1771431795550,"user_tz":480,"elapsed":854,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}},"outputId":"d271fa54-0679-4af6-a625-046ef36c1b12"},"source":["# ============================================================\n","# BUILD: Aggregated By Year (for QC comparison)\n","# ============================================================\n","\n","agg_by_year = []\n","\n","# Aggregate monthly_data to yearly totals per SKU\n","total_monthly = monthly_data.groupby(['year_month_str', 'products__variants__sku'])['quantity'].sum().reset_index()\n","total_monthly['year'] = total_monthly['year_month_str'].str[:4]\n","\n","for sku in sku_details['products__variants__sku'].unique():\n","    sku_info = sku_details[sku_details['products__variants__sku'] == sku].iloc[0]\n","    sku_data = total_monthly[total_monthly['products__variants__sku'] == sku]\n","\n","    yearly = sku_data.groupby('year')['quantity'].sum()\n","\n","    # 2026: Jan YTD actual\n","    ytd_2026 = int(sku_data[sku_data['year_month_str'] == '2026-01']['quantity'].sum())\n","\n","    # 2026 Forecast: sum from forecast_df\n","    sku_fcst_2026 = forecast_df[\n","        (forecast_df['sku'] == sku) & (forecast_df['channel'] == 'TOTAL')\n","    ]['forecast_qty'].sum()\n","\n","    total_2026 = ytd_2026 + int(sku_fcst_2026)\n","\n","    is_active = sku in active_skus_from_file\n","\n","    agg_by_year.append({\n","        'SKU': sku,\n","        'Product_Name': sku_info['product_name'],\n","        'Is_Active': 'Yes' if is_active else 'No',\n","        '2024': int(yearly.get('2024', 0)),\n","        '2025': int(yearly.get('2025', 0)),\n","        '2026_YTD': ytd_2026,\n","        '2026_Forecast': total_2026\n","    })\n","\n","agg_by_year_df = pd.DataFrame(agg_by_year)\n","print(f\"\\n‚úÖ Aggregated By Year built: {len(agg_by_year_df)} SKUs\")\n","print(f\"   Columns: {list(agg_by_year_df.columns)}\")\n"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚úÖ Aggregated By Year built: 275 SKUs\n","   Columns: ['SKU', 'Product_Name', 'Is_Active', '2024', '2025', '2026_YTD', '2026_Forecast']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212},"id":"tvNqWVe_YX7u","executionInfo":{"status":"ok","timestamp":1771431806141,"user_tz":480,"elapsed":7755,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}},"outputId":"60a45fdf-38ad-450e-9e24-0db0b0c9c350"},"source":["# ============================================================\n","# UPLOAD: QC Check CSV\n","# ============================================================\n","# Upload a CSV with columns: finished_good, sales_2024, sales_2025, sales_2026\n","# This will be compared against the forecast data for quality checking\n","\n","print(\"üìÇ Upload your QC check CSV file\")\n","print(\"   Expected columns: finished_good, sales_2024, sales_2025, sales_2026\")\n","print()\n","\n","try:\n","    qc_files = files.upload()\n","    if qc_files:\n","        qc_filename = list(qc_files.keys())[0]\n","        print(f\"\\nLoading QC data from: {qc_filename}\")\n","\n","        qc_data = pd.read_csv(qc_filename)\n","\n","        # Rename columns to match\n","        qc_data = qc_data.rename(columns={'finished_good': 'SKU'})\n","\n","        print(f\"‚úÖ QC data loaded: {len(qc_data)} SKUs\")\n","        print(f\"   Columns: {list(qc_data.columns)}\")\n","        print(f\"   Sample SKUs: {qc_data[\"SKU\"].head(3).tolist()}\")\n","    else:\n","        qc_data = None\n","        print(\"‚ö†Ô∏è  No QC file uploaded - skipping QC check\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è  Error loading QC file: {e}\")\n","    qc_data = None\n"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["üìÇ Upload your QC check CSV file\n","   Expected columns: finished_good, sales_2024, sales_2025, sales_2026\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-1c7e1bab-d4ae-4088-ab19-21617931904f\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-1c7e1bab-d4ae-4088-ab19-21617931904f\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving active items - qc check.csv to active items - qc check.csv\n","\n","Loading QC data from: active items - qc check.csv\n","‚úÖ QC data loaded: 57 SKUs\n","   Columns: ['SKU', 'sales_2024', 'sales_2025', 'sales_2026']\n","   Sample SKUs: ['FG-10004', 'FG-10005', 'FG-10006']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeIHv4QdYX7u","executionInfo":{"status":"ok","timestamp":1771431809469,"user_tz":480,"elapsed":1321,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}},"outputId":"df91a0cc-7789-445d-8c2e-0cf334cb5bd8"},"source":["# ============================================================\n","# QC COMPARISON & SHEET CREATION\n","# ============================================================\n","\n","if qc_data is not None:\n","    print(\"\\nBuilding QC comparison...\")\n","\n","    # Merge forecast data with QC data\n","    qc_comparison = agg_by_year_df.merge(\n","        qc_data,\n","        on='SKU',\n","        how='outer',\n","        suffixes=('', '_QC')\n","    )\n","\n","    # Calculate deltas\n","    qc_comparison['Delta_2024'] = qc_comparison['2024'] - qc_comparison['sales_2024'].fillna(0)\n","    qc_comparison['Delta_2025'] = qc_comparison['2025'] - qc_comparison['sales_2025'].fillna(0)\n","    qc_comparison['Delta_2026_YTD'] = qc_comparison['2026_YTD'] - qc_comparison['sales_2026'].fillna(0)\n","\n","    # Reorder columns for clarity\n","    qc_comparison = qc_comparison[[\n","        'SKU', 'Product_Name', 'Is_Active',\n","        '2024', 'sales_2024', 'Delta_2024',\n","        '2025', 'sales_2025', 'Delta_2025',\n","        '2026_YTD', 'sales_2026', 'Delta_2026_YTD',\n","        '2026_Forecast'\n","    ]]\n","\n","    # Fill NaN with 0 for cleaner display\n","    qc_comparison = qc_comparison.fillna(0).astype({\n","        '2024': int, 'sales_2024': int, 'Delta_2024': int,\n","        '2025': int, 'sales_2025': int, 'Delta_2025': int,\n","        '2026_YTD': int, 'sales_2026': int, 'Delta_2026_YTD': int,\n","        '2026_Forecast': int\n","    })\n","\n","    print(f\"‚úÖ QC comparison built: {len(qc_comparison)} SKUs\")\n","    print(f\"\\nSummary:\")\n","    print(f\"  Total Delta 2024: {qc_comparison['Delta_2024'].sum():,}\")\n","    print(f\"  Total Delta 2025: {qc_comparison['Delta_2025'].sum():,}\")\n","    print(f\"  Total Delta 2026 YTD: {qc_comparison['Delta_2026_YTD'].sum():,}\")\n","\n","    # Write QC sheet\n","    print(\"\\nWriting QC Check sheet...\")\n","    ws_qc = sh.add_worksheet(title='QC Check', rows=1000, cols=15)\n","\n","    header = [\n","        'SKU', 'Product Name', 'Is Active',\n","        'Forecast 2024', 'QC 2024', 'Delta 2024',\n","        'Forecast 2025', 'QC 2025', 'Delta 2025',\n","        'Forecast 2026 YTD', 'QC 2026', 'Delta 2026 YTD',\n","        'Forecast 2026 Total'\n","    ]\n","\n","    data_rows = [header] + qc_comparison.values.tolist()\n","    ws_qc.update('A1', data_rows)\n","\n","    # Format header\n","    ws_qc.format('A1:M1', {\n","        'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},\n","        'backgroundColor': {'red': 0.259, 'green': 0.522, 'blue': 0.957}\n","    })\n","\n","    # Highlight delta columns in yellow\n","    ws_qc.format('F:F', {'backgroundColor': {'red': 1, 'green': 1, 'blue': 0.8}})  # Delta 2024\n","    ws_qc.format('I:I', {'backgroundColor': {'red': 1, 'green': 1, 'blue': 0.8}})  # Delta 2025\n","    ws_qc.format('L:L', {'backgroundColor': {'red': 1, 'green': 1, 'blue': 0.8}})  # Delta 2026 YTD\n","\n","    print(f\"  ‚úÖ QC Check sheet created with {len(data_rows)} rows\")\n","else:\n","    print(\"\\n‚ö†Ô∏è  Skipping QC comparison (no QC data uploaded)\")\n"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Building QC comparison...\n","‚úÖ QC comparison built: 275 SKUs\n","\n","Summary:\n","  Total Delta 2024: 22,286\n","  Total Delta 2025: 15,879\n","  Total Delta 2026 YTD: -4,380\n","\n","Writing QC Check sheet...\n","  ‚úÖ QC Check sheet created with 276 rows\n"]}]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7LqSQWSYxoRy","outputId":"fd609534-2472-4f5e-8cde-3c283f47cf55","executionInfo":{"status":"ok","timestamp":1771431811860,"user_tz":480,"elapsed":166,"user":{"displayName":"Kenneth Lekashman","userId":"06957948482640280197"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","DEMAND PLANNING TOOL v3 CREATED SUCCESSFULLY!\n","================================================================================\n","\n","Google Sheet Name: Demand_Planning_20260218_1622\n","URL: https://docs.google.com/spreadsheets/d/18330-VAQg6Cd-kWFujImQ8agIyUwqH_qWRzb6_obE6k\n","\n","Sheets created:\n","  - Summary Dashboard\n","  - Product Type Breakdown\n","  - Direct-to-Consumer - Forecast\n","  - Wholesale - Forecast\n","  - TOTAL - Forecast\n","  - Agg by Month ‚Äî Direct-to-Consumer\n","  - Agg by Month ‚Äî Wholesale\n","  - Agg by Month ‚Äî TOTAL\n","  - Building Blocks\n","  - QC Check\n","\n","Total SKUs analyzed: 275\n","Channels: Direct-to-Consumer, Wholesale, TOTAL\n","Forecast period: Feb 2026 - Dec 2026\n","\n","What's new in v3:\n","  ‚úÖ Seasonality by PRODUCT TYPE (24-month pooled indices, not per-item)\n","  ‚úÖ Seasonality table in Product Type Breakdown tab (month √ó product type)\n","  ‚úÖ Forecast sheets show 2024 + 2025 actuals alongside 2026 forecast\n","  ‚úÖ Actual vs Forecast columns color-coded (slate = actual, green = forecast)\n","  ‚úÖ Channel total row added to each forecast sheet\n","  ‚úÖ Aggregated By Month ‚Äî 3 channel tabs (Wholesale / DTC / TOTAL), SKU √ó month rows\n","  ‚úÖ Building Blocks tab: Raw 2025 | Seasonal Index | Deseasonalized | Base | Trend | Forecast\n","  ‚úÖ Inactivity rule: SKUs with 0 sales in last 6 months excluded from all forecasts\n","  ‚úÖ Per-channel growth rate overrides (CHANNEL_GROWTH_RATES dict)\n"]}],"source":["# Final output\n","print(\"\\n\" + \"=\"*80)\n","print(\"DEMAND PLANNING TOOL v3 CREATED SUCCESSFULLY!\")\n","print(\"=\"*80)\n","print(f\"\\nGoogle Sheet Name: {sheet_name}\")\n","print(f\"URL: https://docs.google.com/spreadsheets/d/{sh.id}\")\n","print(f\"\\nSheets created:\")\n","for worksheet in sh.worksheets():\n","    print(f\"  - {worksheet.title}\")\n","print(f\"\\nTotal SKUs analyzed: {len(sku_details)}\")\n","print(f\"Channels: {', '.join(all_channels)}\")\n","print(f\"Forecast period: Feb 2026 - Dec 2026\")\n","print(f\"\\nWhat's new in v3:\")\n","print(f\"  ‚úÖ Seasonality by PRODUCT TYPE (24-month pooled indices, not per-item)\")\n","print(f\"  ‚úÖ Seasonality table in Product Type Breakdown tab (month √ó product type)\")\n","print(f\"  ‚úÖ Forecast sheets show 2024 + 2025 actuals alongside 2026 forecast\")\n","print(f\"  ‚úÖ Actual vs Forecast columns color-coded (slate = actual, green = forecast)\")\n","print(f\"  ‚úÖ Channel total row added to each forecast sheet\")\n","print(f\"  ‚úÖ Aggregated By Month ‚Äî 3 channel tabs (Wholesale / DTC / TOTAL), SKU √ó month rows\")\n","print(f\"  ‚úÖ Building Blocks tab: Raw 2025 | Seasonal Index | Deseasonalized | Base | Trend | Forecast\")\n","print(f\"  ‚úÖ Inactivity rule: SKUs with 0 sales in last 6 months excluded from all forecasts\")\n","print(f\"  ‚úÖ Per-channel growth rate overrides (CHANNEL_GROWTH_RATES dict)\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbformat_minor":4,"pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}